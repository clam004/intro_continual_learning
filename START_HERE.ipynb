{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 intuition behind elastic weight colsolidation\n",
    "\n",
    "In the figure below, $\\theta^{*}$ are the weights (ie parameters, synaptic strengths) learned by the neural network (NN) to solve old task A, shown as a vector in vector space. ie if this neural network as 100 total weights then this is a 2D representation of $\\mathbb{R}^{100}$ space. The blue horizontal arrow shows an example of catastrophic forgetting, whereby $\\theta^{*}$ moves out of the region that allows the NN to perform well at task A (grey), and into the center of a region that allows the NN to perform well at task B (cream). The downward green arrow is the update to $\\theta^{*}$ regularized by L2 penalty $\\alpha (\\theta_{i} - \\theta_{A , i}^{*})^{2}$ that causes it to move toward the cream region irrespective of the shape of the grey region. The desired update vector is the red arrow that moves the NN weights into a region capable of performing well at both tasks A and B. \n",
    "\n",
    "How Elastic Weight Cosolidation Changes Learning New Weights $\\theta^{*}$\n",
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/clam004/intro_continual_learning/main/files/F1.large.jpg\" height=500 width=500 >\n",
    "</p>\n",
    "\n",
    "EWC encourages movement of weights along the red path by modifying the loss function when re-training a NN that has already been trained to convergence using the loss function for task A, $L_{A}$, which has settled on weights $\\theta_{A}$. When re-training the NN on task B using $L_{B}$, we add a term which penalizes changes to weights that are both far from $\\theta_{A}$, ie $(\\theta_{i} - \\theta_{A , i}^{*})^{2}$, and also high in $F_{i}$ which encodes the shape of the grey region.\n",
    "\n",
    "$$L \\left(\\right. \\theta \\left.\\right) = L_{B} \\left(\\right. \\theta \\left.\\right) + \\underset{i}{\\sum} \\frac{\\lambda}{2} F_{i} \\left(\\theta_{i} - \\theta_{A , i}^{*}\\right)^{2} $$\n",
    "\n",
    "### But what is F? \n",
    "\n",
    "F is the Fisher information matrix. We want to use the diagonal components in Fisher Information Matrix to identify which parameters are more important to task A and apply higher weights to them (the direction of the short axis of grey oval). To learn B we should instead change those weights where F_i is small (long axis of grey oval).  \n",
    "\n",
    "In the EWC paper:\n",
    "\n",
    "\"we approximate the posterior as a Gaussian distribution with mean given by the parameters θ∗A and a diagonal precision given by the diagonal of the Fisher information matrix F. F has three key properties (20): (i) It is equivalent to the second derivative of the loss near a minimum, (ii) it can be computed from first-order derivatives alone and is thus easy to calculate even for large models, and (iii) it is guaranteed to be positive semidefinite. Note that this approach is similar to expectation propagation where each subtask is seen as a factor of the posterior (21). where LB(θ) is the loss for task B only, λ sets how important the old task is compared with the new one, and i labels each parameter.\n",
    "\n",
    "When moving to a third task, task C, EWC will try to keep the network parameters close to the learned parameters of both tasks A and B. This can be enforced either with two separate penalties or as one by noting that the sum of two quadratic penalties is itself a quadratic penalty.\"\n",
    "\n",
    "### Lets learn what F is in the example\n",
    "\n",
    "This article gives a very good explaination of F in the context of EWC: [fisher-info-matrix](https://andrewliao11.github.io/blog/fisher-info-matrix/)\n",
    "\n",
    "To compute F_i, we sample the data from task A once and calculate the empirical Fisher Information Matrix. \n",
    "\n",
    "$$\n",
    "I_{\\theta_\\mathcal{A}^*} = \\frac{1}{N}  \\sum_{i=1}^{N} \\nabla_\\theta log \\ p(x_{\\mathcal{A}, i}|\\theta_\\mathcal{A}^*) \\nabla_\\theta log \\ p(x_{\\mathcal{A}, i}|\\theta_\\mathcal{A}^*)^T\n",
    "$$\n",
    "\n",
    "This is just to say that the above equation is how you calculate the below equation from the data. For each pair of parameters in $\\theta$ ($\\theta_i$ and $\\theta_j$), the Fisher Information matrix at position ij is\n",
    "\n",
    "$$\n",
    "I(\\theta)_{ij} = E\\left[ \\left( \\frac{\\partial}{\\partial\\theta_i}\\log f(X;\\theta) \\right)\\left( \\frac{\\partial}{\\partial\\theta_j}\\log f(X;\\theta) \\right) \\mid \\theta\\right]\n",
    "$$\n",
    "\n",
    "If this equation is hard to understand, then the code should make it clearer, dont worry, we will match parts of the code to the equation above so it becomes more tangible.\n",
    "\n",
    "# Part 2 A look at the data and the task\n",
    "\n",
    "### MNIST\n",
    "\n",
    "The MNIST data set contains 70,000 images of handwritten digits and their corresponding labels. The images are 28x28 with pixel values from 0 to 255. The labels are the digits from 0 to 9. By default 60,000 of these images belong to a training set and 10,000 of these images belong to a test set.\n",
    "\n",
    "### Fashion-MNIST\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot\n",
    "\n",
    "## Task\n",
    "\n",
    "as you might guess, our goal is to train an NN that retains it's ability to perform well on MNIST after being retrained on only Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from contlearn.getdata import getMNIST, getFashionMNIST\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_mnist, test_loader_mnist = getMNIST(batch_size=64)\n",
    "train_loader_fashion, test_loader_fashion = getFashionMNIST(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7603f2c490>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image, target_label = next(iter(train_loader_mnist))\n",
    "\n",
    "print(target_label[0])\n",
    "print(input_image[0][0].shape)\n",
    "\n",
    "img = Image.fromarray(input_image[0][0].detach().cpu().numpy()*255)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7603e39c10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image, target_label = next(iter(train_loader_fashion))\n",
    "\n",
    "fashion_key = {\n",
    "0: \"T-shirt/top\",\n",
    "1: \"Trouser\",\n",
    "2: \"Pullover\",\n",
    "3: \"Dress\",\n",
    "4: \"Coat\",\n",
    "5: \"Sandal\",\n",
    "6: \"Shirt\",\n",
    "7: \"Sneaker\",\n",
    "8: \"Bag\",\n",
    "9: \"Ankle boot\",\n",
    "}\n",
    "\n",
    "print(fashion_key[int(target_label[0].detach().cpu().numpy())])\n",
    "print(input_image[0][0].shape)\n",
    "\n",
    "img = Image.fromarray(input_image[0][0].detach().cpu().numpy()*255)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Baseline results\n",
    "\n",
    "first we train on MNIST and the we will observe the drop in performance once we retrain on Fashion-MNIST, WITHOUT Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "you are using PyTorch version  1.10.0+cu102\n",
      "you have 2 GPUs\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from contlearn.getmodels import MLP\n",
    "from contlearn.gettrainer import one_epoch_baseline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "print('you are using PyTorch version ',torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    print(\"you have\", torch.cuda.device_count(), \"GPUs\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(device)\n",
    "else:\n",
    "    use_cuda = False\n",
    "    print('no GPUs detected')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(hidden_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_training(model, epochs, use_cuda=True, weight=True):\n",
    "    \n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    loss, acc = {}, {}\n",
    "    \n",
    "    for task in ['mnist', 'fashion']:\n",
    "        \n",
    "        loss[task] = []\n",
    "        acc[task] = []\n",
    "        \n",
    "        if task == 'mnist':\n",
    "            train_loader = train_loader_mnist\n",
    "        else:\n",
    "            train_loader = train_loader_fashion\n",
    "            \n",
    "        \n",
    "        for _ in tqdm(range(epochs)):\n",
    "            \n",
    "            epoch_loss = one_epoch_baseline(model,optimizer,train_loader)\n",
    "            \n",
    "            loss[task].append()\n",
    "            \n",
    "            for sub_task in range(task + 1):\n",
    "                acc[sub_task].append(test(model, test_loader))\n",
    "        if task == 0 and weight:\n",
    "            weight = model.state_dict()\n",
    "    return loss, acc, weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
